{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T03:19:06.164018Z",
     "iopub.status.busy": "2024-06-23T03:19:06.163814Z",
     "iopub.status.idle": "2024-06-23T03:19:09.898816Z",
     "shell.execute_reply": "2024-06-23T03:19:09.898214Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.layers import Permute\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score\n",
    "\n",
    "from Dataset import config\n",
    "from Dataset.EEGDataset_SOTA import EEGDataset\n",
    "from Dataset.misc import subject_run_map\n",
    "from utils.analyzer import stats\n",
    "from utils.wrapper_SOTA import ModelWrapper\n",
    "from utils.callbacks import SimpMovAve\n",
    "from utils.seed import set_seeds\n",
    "from utils.gpu import gpu_allocation\n",
    "from utils.log import Logging, dict_pad, save_checkpoint, load_checkpoint\n",
    "\n",
    "from SOTA.SOTA_Model import SOTA_Models\n",
    "from SOTA.preprocessing import standardize_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T03:19:09.902254Z",
     "iopub.status.busy": "2024-06-23T03:19:09.902126Z",
     "iopub.status.idle": "2024-06-23T03:19:09.952960Z",
     "shell.execute_reply": "2024-06-23T03:19:09.952310Z"
    }
   },
   "outputs": [],
   "source": [
    "GPU_ALLOCATION = None # None | GPU Memory Limit in GB\n",
    "\n",
    "gpu_allocation(GPU_ALLOCATION) if GPU_ALLOCATION else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T03:19:09.956462Z",
     "iopub.status.busy": "2024-06-23T03:19:09.956105Z",
     "iopub.status.idle": "2024-06-23T03:19:09.959967Z",
     "shell.execute_reply": "2024-06-23T03:19:09.959303Z"
    }
   },
   "outputs": [],
   "source": [
    "ONE_HOT = True # Bool\n",
    "DATASET_PATH = 'RESOURCES'\n",
    "\n",
    "EEG_DATASET_CONFIG = {\n",
    "    'normalization': True, # None | 'batch' | 'channel' | 'time' | 'time-batch'\n",
    "\n",
    "    'signal_duration': None, # None for Default Dataset tmin & tmax config | [tmin, tmax]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'BCICIV2A'        # 'BCICIV2A' | 'EEGMMIDB'\n",
    "\n",
    "SUBJECT_SELECTION = 'SL'    # 'SL' | 'SM' | 'SN'\n",
    "SESSION_SELECTION = 'DS'    # 'DS' | 'RS'\n",
    "FINE_TUNING = False         # for 'SL-DS-FT' using 'SN' Top Models as baseline\n",
    "\n",
    "VARY_VALID_RUN = True       # True for DS: LOSeO\n",
    "KFOLD = False               # True for SN: LSSO | False for SN: LOSO \n",
    "\n",
    "CLASS = 4                   # (int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == 'BCICIV2A':\n",
    "    SUBJECTS = [subj for subj in range(1, 10)]\n",
    "    VALID_RUN = [[True],\n",
    "                 [False]] # [False, True]\n",
    "\n",
    "    EVENTS = ['Left Hand', 'Right Hand', 'Feet', 'Tongue']\n",
    "    SUBJECT_EXEMPTION = config.dataset_BCICIV2A.subject_exemption\n",
    "    DATALOADER_KWARGS = {}\n",
    "\n",
    "elif DATASET == 'EEGMMIDB':\n",
    "    SUBJECTS = [subj for subj in range(1, 110)]\n",
    "    VALID_RUN = [[4, 6],\n",
    "                 [8, 10],\n",
    "                 [12, 14]]  # [4, 6, 8, 10, 12, 14]\n",
    "\n",
    "    SUBJECT_EXEMPTION = config.dataset_EEGMMIDB.subject_exemption\n",
    "    EVENTS = ['Left Fist', 'Right Fist', 'Both Fists', 'Both Feet']\n",
    "    DATALOADER_KWARGS = {'Epochs_proj': False}\n",
    "    \n",
    "SUBJECT_SIZE = len(SUBJECTS)\n",
    "SUBJECT_SIZE = 1 if (SUBJECT_SELECTION == 'SM') else SUBJECT_SIZE\n",
    "SUBJECT_SIZE = 5 if (SUBJECT_SELECTION == 'SN' and KFOLD) else SUBJECT_SIZE # 20% train-test split\n",
    "\n",
    "EVENTS = EVENTS[:CLASS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T03:19:09.970087Z",
     "iopub.status.busy": "2024-06-23T03:19:09.969768Z",
     "iopub.status.idle": "2024-06-23T03:19:09.976027Z",
     "shell.execute_reply": "2024-06-23T03:19:09.975340Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset(DATASET, SUBJECT_SELECTION, SESSION_SELECTION, SUBJECT, VALID_RUN, SEED=42):\n",
    "\n",
    "    (TRAIN_SUBJECT, TRAIN_RUN), (VALID_SUBJECT, VALID_RUN) = subject_run_map(DATASET, SUBJECT_SELECTION, SESSION_SELECTION, SUBJECT, VALID_RUN)\n",
    "\n",
    "    X, y = EEGDataset(DATASET, {i: TRAIN_RUN for i in TRAIN_SUBJECT}, EVENTS,\n",
    "                      EEG_DATASET_CONFIG,\n",
    "                      one_hot=ONE_HOT, dataset_path=DATASET_PATH,\n",
    "                      **DATALOADER_KWARGS)\n",
    "\n",
    "    if SESSION_SELECTION == 'RS':\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=SEED)\n",
    "\n",
    "        del X, y\n",
    "        \n",
    "    else: # 'DS'\n",
    "        X_train, y_train = X, y\n",
    "        X_test, y_test = EEGDataset(DATASET, {i: VALID_RUN for i in VALID_SUBJECT}, EVENTS,\n",
    "                                    EEG_DATASET_CONFIG,\n",
    "                                    one_hot=ONE_HOT, dataset_path=DATASET_PATH,\n",
    "                                    **DATALOADER_KWARGS)\n",
    "\n",
    "    # X: (S, N, T, 1)\n",
    "    if EEG_DATASET_CONFIG['normalization']:\n",
    "        X_train, X_test = standardize_data(X_train, X_test, axis=-3) # wrt CH axis\n",
    "        \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T03:19:09.979371Z",
     "iopub.status.busy": "2024-06-23T03:19:09.979005Z",
     "iopub.status.idle": "2024-06-23T03:19:09.997786Z",
     "shell.execute_reply": "2024-06-23T03:19:09.997092Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'DB-ATCNet'    # 'EEGNet' | 'EEG-TCNet' | 'TCNet-Fusion' | 'ATCNet' | 'DB-ATCNet' \n",
    "\n",
    "class EEG_Model(ModelWrapper):\n",
    "    def __init__(self, classes):\n",
    "        super().__init__(classes)\n",
    "        \n",
    "        self.eeg = SOTA_Models(MODEL_NAME)\n",
    "\n",
    "    def call(self, input):\n",
    "\n",
    "        out = Permute((3,1,2))(input)\n",
    "        # (1, N, T)\n",
    "        out = self.eeg(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T03:19:10.000744Z",
     "iopub.status.busy": "2024-06-23T03:19:10.000458Z",
     "iopub.status.idle": "2024-06-23T03:19:10.004771Z",
     "shell.execute_reply": "2024-06-23T03:19:10.004177Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_TRAIN = 10\n",
    "LOAD_CHECKPOINT = True\n",
    "\n",
    "KFOLD_SPLIT_SIZE = 5\n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "MOV_WINDOW_SIZE = 20\n",
    "MOV_AVE = True\n",
    "MOV_STD = True\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "LOSS = 'CCE' if CLASS > 2 else 'BCE' # 'BCE' | 'CCE' | 'Loge'\n",
    "\n",
    "OPTIMIZER = 'Adam' # 'Adam' | 'AdamW'\n",
    "if not FINE_TUNING:\n",
    "    LR = 0.0009 \n",
    "else:\n",
    "    LR = 0.0009\n",
    "WEIGHT_DECAY = None\n",
    "AMSGRAD = False\n",
    "\n",
    "# LR_SCHED_METRIC = 'val_loss' # 'val_loss' | 'mov_ave_val_loss'\n",
    "# LR_SCHED_DECAY = 0.9\n",
    "# LR_SCHED_MIN = 0.0001\n",
    "# LR_SCHED_PATIENCE = 10\n",
    "# LR_SCHED_COOLDOWN = 0\n",
    "\n",
    "TARGET_METRIC = 'val_accuracy' # 'val_accuracy' | 'mov_ave_val_accuracy'\n",
    "EARLY_STOP_PATIENCE = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T03:19:10.015929Z",
     "iopub.status.busy": "2024-06-23T03:19:10.015701Z",
     "iopub.status.idle": "2024-06-23T10:03:11.075171Z",
     "shell.execute_reply": "2024-06-23T10:03:11.074617Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "\n",
    "TRAINING_CASE = SUBJECT_SELECTION  if SUBJECT_SELECTION == 'SN' else SUBJECT_SELECTION + '-' + SESSION_SELECTION\n",
    "TRAINING_CASE = TRAINING_CASE + '-FT' if FINE_TUNING else TRAINING_CASE\n",
    "TRAINING_CASE = DATASET +'-'+ TRAINING_CASE\n",
    "results_path = os.path.join(os.getcwd(), '.results', MODEL_NAME, TRAINING_CASE)\n",
    "if not os.path.exists(results_path):\n",
    "    os.makedirs(results_path)\n",
    "checkpoint_path = results_path + '/checkpoint.json'\n",
    "\n",
    "log_write = Logging(results_path + '/log.txt')\n",
    "\n",
    "if LOAD_CHECKPOINT and os.path.exists(checkpoint_path):\n",
    "    # LOAD Last Train Config\n",
    "    SUBJ_INIT, SUBJ_TRAIN_INIT, SUBJ_SUMMARY, OVERALL_SUMMARY = load_checkpoint(file_path=checkpoint_path)\n",
    "\n",
    "    # Load Next Train Config\n",
    "    if SUBJ_SUMMARY:\n",
    "        SUBJ_INIT += 1\n",
    "        SUBJ_TRAIN_INIT = 1\n",
    "    else:\n",
    "        SUBJ_TRAIN_INIT += 1\n",
    "\n",
    "    # Load Checkpoint Data\n",
    "    data = np.load(results_path + '/model_performance.npz')\n",
    "    \n",
    "    train_seed = data['train_seed']\n",
    "    inference_time = data['inference_time']\n",
    "\n",
    "    test_acc = data['test_acc']\n",
    "    test_kappa = data['test_kappa']\n",
    "    test_loss = data['test_loss']\n",
    "    \n",
    "    min_test_loss = data['min_test_loss']\n",
    "    \n",
    "    max_test_mov_ave_acc = data['max_test_mov_ave_acc']\n",
    "    min_test_mov_ave_loss = data['min_test_mov_ave_loss']\n",
    "\n",
    "    best_runs = data['best_runs']\n",
    "    best_test_acc = data['best_test_acc']\n",
    "    best_test_kappa = data['best_test_kappa']\n",
    "    best_test_loss = data['best_test_loss']\n",
    "    best_min_test_loss = data['best_min_test_loss']\n",
    "\n",
    "    best_mov_ave_runs = data['best_mov_ave_runs']\n",
    "    best_max_test_mov_ave_acc = data['best_max_test_mov_ave_acc']\n",
    "    best_min_test_mov_ave_loss = data['best_min_test_mov_ave_loss']\n",
    "\n",
    "    log_write.write('\\n\\n-----LOAD CHECKPOINT-----\\n')\n",
    "\n",
    "    CHECKPOINT_LOADED = True\n",
    "\n",
    "else:\n",
    "    # NO CHECKPOINT\n",
    "    SUBJ_INIT = 1\n",
    "    SUBJ_TRAIN_INIT = 1\n",
    "    OVERALL_SUMMARY = False\n",
    "\n",
    "    log_write.write(MODEL_NAME + '\\t' + TRAINING_CASE + '\\n')\n",
    "\n",
    "    # Initialize Data\n",
    "    train_seed = np.zeros((SUBJECT_SIZE, NUM_TRAIN))\n",
    "    inference_time = np.zeros((SUBJECT_SIZE, NUM_TRAIN))\n",
    "\n",
    "    test_acc = np.zeros((SUBJECT_SIZE, NUM_TRAIN))\n",
    "    test_kappa = np.zeros((SUBJECT_SIZE, NUM_TRAIN))\n",
    "    test_loss = np.zeros((SUBJECT_SIZE, NUM_TRAIN))\n",
    "\n",
    "    min_test_loss = np.zeros((SUBJECT_SIZE, NUM_TRAIN))\n",
    "\n",
    "    max_test_mov_ave_acc = np.zeros((SUBJECT_SIZE, NUM_TRAIN))\n",
    "    min_test_mov_ave_loss = np.zeros((SUBJECT_SIZE, NUM_TRAIN))\n",
    "\n",
    "    best_runs = np.zeros(SUBJECT_SIZE, dtype=np.int8)\n",
    "    best_test_acc = np.zeros(SUBJECT_SIZE)\n",
    "    best_test_kappa = np.zeros(SUBJECT_SIZE)\n",
    "    best_test_loss = np.zeros(SUBJECT_SIZE)\n",
    "    best_min_test_loss = np.zeros(SUBJECT_SIZE)\n",
    "\n",
    "    best_mov_ave_runs = np.zeros(SUBJECT_SIZE, dtype=np.int8)\n",
    "    best_max_test_mov_ave_acc = np.zeros(SUBJECT_SIZE)\n",
    "    best_min_test_mov_ave_loss = np.zeros(SUBJECT_SIZE)\n",
    "\n",
    "    CHECKPOINT_LOADED = False\n",
    "\n",
    "if KFOLD:\n",
    "    kf = KFold(n_splits=KFOLD_SPLIT_SIZE, shuffle=False)\n",
    "    SUBJECT_KFOLD_SPLIT = [kf_split[1]+1 for kf_split in list(kf.split(SUBJECTS))]\n",
    "\n",
    "for subj in range(SUBJ_INIT-1, SUBJECT_SIZE):\n",
    "    log_write.write('\\nTraining Subject {:d}\\n'.format(subj+1))\n",
    "\n",
    "    if subj+1 in SUBJECT_EXEMPTION and (SUBJECT_SELECTION == 'SL' or (SUBJECT_SELECTION == 'SN' and not KFOLD)):\n",
    "        train_seed[subj] = np.full(NUM_TRAIN, np.nan)\n",
    "        inference_time[subj] = np.full(NUM_TRAIN, np.nan)\n",
    "\n",
    "        test_acc[subj] = np.full(NUM_TRAIN, np.nan)\n",
    "        test_kappa[subj] = np.full(NUM_TRAIN, np.nan)\n",
    "        test_loss[subj] = np.full(NUM_TRAIN, np.nan)\n",
    "\n",
    "        min_test_loss[subj] = np.full(NUM_TRAIN, np.nan)\n",
    "\n",
    "        max_test_mov_ave_acc[subj] = np.full(NUM_TRAIN, np.nan)\n",
    "        min_test_mov_ave_loss[subj] = np.full(NUM_TRAIN, np.nan)\n",
    "\n",
    "        best_runs[subj] = 0\n",
    "        best_test_acc[subj] = np.nan\n",
    "        best_test_kappa[subj] = np.nan\n",
    "        best_test_loss[subj] = np.nan\n",
    "        best_min_test_loss[subj] = np.nan\n",
    "\n",
    "        best_mov_ave_runs[subj] = 0\n",
    "        best_max_test_mov_ave_acc[subj] = np.nan\n",
    "        best_min_test_mov_ave_loss[subj] = np.nan\n",
    "        \n",
    "        log_write.write('SKIPPED\\n')\n",
    "\n",
    "        with open(results_path + '/model_performance.npz', 'wb') as model_performance:\n",
    "            np.savez(model_performance,\n",
    "                    train_seed=train_seed, inference_time=inference_time, \n",
    "                    test_acc=test_acc, test_kappa=test_kappa, test_loss=test_loss, min_test_loss=min_test_loss,\n",
    "                    max_test_mov_ave_acc=max_test_mov_ave_acc, min_test_mov_ave_loss=min_test_mov_ave_loss, \n",
    "                    best_runs=best_runs, best_test_acc=best_test_acc, best_test_kappa=best_test_kappa, best_test_loss=best_test_loss, best_min_test_loss=best_min_test_loss,\n",
    "                    best_mov_ave_runs=best_mov_ave_runs, best_max_test_mov_ave_acc=best_max_test_mov_ave_acc, best_min_test_mov_ave_loss=best_min_test_mov_ave_loss)\n",
    "        print('Model Performance Saved')\n",
    "\n",
    "        save_checkpoint(subj+1, NUM_TRAIN, subject_summary=True, file_path=checkpoint_path)\n",
    "        print('-----CHECKPOINT-----')\n",
    "\n",
    "        continue\n",
    "\n",
    "    subject_list = SUBJECT_KFOLD_SPLIT[subj] if (SUBJECT_SELECTION in ['SN'] and KFOLD) else [subj+1]\n",
    "\n",
    "    if SESSION_SELECTION == 'DS' and not VARY_VALID_RUN:\n",
    "        X_train, y_train, X_test, y_test = load_dataset(DATASET, SUBJECT_SELECTION, SESSION_SELECTION, subject_list, VALID_RUN[0])\n",
    "        print('Subject {:d} Dataset Loaded'.format(subj+1))\n",
    "        print(X_train.shape)\n",
    "        print(X_test.shape)\n",
    "\n",
    "    subj_path = results_path + '/subj-{:d}'.format(subj+1)\n",
    "    if not os.path.exists(subj_path):\n",
    "        os.makedirs(subj_path)\n",
    "\n",
    "    for train_run in range(SUBJ_TRAIN_INIT-1, NUM_TRAIN):\n",
    "        train_path = subj_path + '/run-{:d}'.format(train_run+1)\n",
    "        best_model_path = train_path + '-best_model.h5'\n",
    "        train_history_path = train_path + '-train_history.csv'\n",
    "        train_plot_path = train_path + '-train_plot.png'\n",
    "        confusion_matrix_path = train_path + '-confusion_matrix.png'\n",
    "        classification_report_path = train_path + '-classification_report.csv'\n",
    "\n",
    "        if VARY_VALID_RUN:\n",
    "            VARY_VALID_RUN_STEP = NUM_TRAIN // len(VALID_RUN)\n",
    "            if ((train_run % VARY_VALID_RUN_STEP) == 0 and (train_run//VARY_VALID_RUN_STEP) < len(VALID_RUN)) or CHECKPOINT_LOADED:\n",
    "                CHECKPOINT_LOADED = False\n",
    "                valid_run_index = train_run//VARY_VALID_RUN_STEP\n",
    "                X_train, y_train, X_test, y_test = load_dataset(DATASET, SUBJECT_SELECTION, SESSION_SELECTION, subject_list, VALID_RUN[valid_run_index])\n",
    "                print('Subject {:d} Dataset {:d} Loaded'.format(subj+1, valid_run_index+1))\n",
    "                print(X_train.shape)\n",
    "                print(X_test.shape)\n",
    "        \n",
    "        SEED = np.random.randint(1e4)\n",
    "        set_seeds(SEED)\n",
    "        train_seed[subj, train_run] = SEED\n",
    "        log_write.write('Subject: {:d}\\tTrain No.: {:d}\\tSeed: {:d}'.format(subj+1, train_run+1, SEED))\n",
    "\n",
    "        if SESSION_SELECTION == 'RS':\n",
    "            X_train, y_train, X_test, y_test = load_dataset(DATASET, SUBJECT_SELECTION, SESSION_SELECTION, subject_list, None, SEED=SEED)\n",
    "            print('Subject {:d} Dataset Loaded'.format(subj+1))\n",
    "            print(X_train.shape)\n",
    "            print(X_test.shape)\n",
    "\n",
    "        model = EEG_Model(EVENTS)\n",
    "        model.build_model(X_train[0].shape).summary()\n",
    "        print('Model Built')\n",
    "\n",
    "        if FINE_TUNING:\n",
    "            model(X_train[:2])\n",
    "\n",
    "            tuned_model_SUBJ = subj+1 if not KFOLD else np.argmax([subj+1 in kf_split for kf_split in SUBJECT_KFOLD_SPLIT])+1\n",
    "\n",
    "            tuned_model_TRAINING_CASE = DATASET +'-'+ 'SN'\n",
    "            tuned_model_TRAINING_CASE = tuned_model_TRAINING_CASE + '-KFold' if KFOLD else tuned_model_TRAINING_CASE\n",
    "            tuned_model_results_path = os.path.join(os.getcwd(), '.results', MODEL_NAME, tuned_model_TRAINING_CASE)\n",
    "            \n",
    "            if VARY_VALID_RUN:\n",
    "                data = np.load(tuned_model_results_path + '/model_performance.npz')\n",
    "                tuned_model_acc = data['max_test_mov_ave_acc']\n",
    "                tuned_model_acc = tuned_model_acc[tuned_model_SUBJ-1]\n",
    "                tuned_model_best_runs = np.argsort(tuned_model_acc)[::-1] + 1\n",
    "\n",
    "                VARY_VALID_RUN_STEP = NUM_TRAIN // len(VALID_RUN)\n",
    "                tuned_model_best_run_index = train_run%VARY_VALID_RUN_STEP\n",
    "                tuned_model_path = tuned_model_results_path + '/subj-{:d}/run-{:d}-best_model.h5'.format(tuned_model_SUBJ, tuned_model_best_runs[tuned_model_best_run_index])\n",
    "\n",
    "            else:\n",
    "                tuned_model_path = tuned_model_results_path + '/subj-{:d}/run-{:d}-best_model.h5'.format(tuned_model_SUBJ, train_run+1)\n",
    "            \n",
    "            model.load_weights(tuned_model_path)\n",
    "\n",
    "        model.compile(loss={'BCE': BinaryCrossentropy(), 'CCE': CategoricalCrossentropy()}[LOSS],\n",
    "                      optimizer=getattr(optimizers, OPTIMIZER, getattr(optimizers.experimental, OPTIMIZER, None))(learning_rate=LR, weight_decay=WEIGHT_DECAY, amsgrad=AMSGRAD),\n",
    "                      metrics=['accuracy'])\n",
    "        print('Model Compiled')\n",
    "\n",
    "        callbacks = [\n",
    "            ModelCheckpoint(best_model_path, monitor=TARGET_METRIC, mode='max' if 'accuracy' in TARGET_METRIC else 'min' if 'loss' in TARGET_METRIC else None, \n",
    "                            save_best_only=True, save_weights_only=True, verbose=0),\n",
    "\n",
    "            # ReduceLROnPlateau(monitor=LR_SCHED_METRIC, mode='max' if 'accuracy' in LR_SCHED_METRIC else 'min' if 'loss' in LR_SCHED_METRIC else None,\n",
    "            #                   factor=LR_SCHED_DECAY, min_lr=LR_SCHED_MIN,\n",
    "            #                   patience=LR_SCHED_PATIENCE, cooldown=LR_SCHED_COOLDOWN, verbose=1),\n",
    "            EarlyStopping(monitor=TARGET_METRIC, mode='max' if 'accuracy' in TARGET_METRIC else 'min' if 'loss' in TARGET_METRIC else None, \n",
    "                          patience=EARLY_STOP_PATIENCE, verbose=1),\n",
    "                          \n",
    "            SimpMovAve('accuracy', MOV_WINDOW_SIZE, mov_ave=MOV_AVE, mov_std=MOV_STD), SimpMovAve('loss', MOV_WINDOW_SIZE, mov_ave=MOV_AVE, mov_std=MOV_STD),\n",
    "            ]\n",
    "\n",
    "        history = model.fit(X_train, y_train,\n",
    "                            validation_data=(X_test, y_test),\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            epochs=EPOCHS, verbose=1, callbacks=callbacks)\n",
    "        \n",
    "        model.plot(mov_ave=MOV_AVE, mov_std=False, grid_on=True).savefig(train_plot_path)\n",
    "        print('Train Plot Saved')\n",
    "\n",
    "        pd.DataFrame(dict_pad(history.history, pad_value=None, pad_pos='leading')).to_csv(train_history_path, index=True)\n",
    "        print('Train History Saved')\n",
    "\n",
    "        model.load_weights(best_model_path)\n",
    "        print('Best Model Loaded')\n",
    "\n",
    "        y_test_round = np.argmax(y_test, axis=1)\n",
    "\n",
    "        in_run = time.time()\n",
    "        test_preds = model.predict(X_test)\n",
    "        out_run = time.time()\n",
    "        test_preds = np.argmax(test_preds, axis=1)\n",
    "        inference_time[subj, train_run] = (out_run - in_run) / len(y_test) * 1000\n",
    "        log_write.write('\\tInference Time: {:.4f} ms'.format(inference_time[subj, train_run]))\n",
    "\n",
    "        test_acc[subj, train_run] = accuracy_score(y_test_round, test_preds)\n",
    "        test_kappa[subj, train_run] = cohen_kappa_score(y_test_round, test_preds)\n",
    "        test_loss[subj, train_run] = model.test(x=X_test, y=y_test)[0]\n",
    "        min_test_loss[subj, train_run] = min(history.history['val_loss'])\n",
    "\n",
    "        max_test_mov_ave_acc[subj, train_run] = max(history.history['mov_ave_val_accuracy'])\n",
    "        min_test_mov_ave_loss[subj, train_run] = min(history.history['mov_ave_val_loss'])\n",
    "        \n",
    "        log_write.write('\\tTest Accuracy: {:.4f}\\tTest Kappa: {:.4f}\\tTest Loss: {:.4f}\\tMIN Test Loss: {:.4f}'.format(\n",
    "            test_acc[subj, train_run], test_kappa[subj, train_run], test_loss[subj, train_run], min_test_loss[subj, train_run]))\n",
    "        log_write.write('\\tMAX Test MovAve Accuracy: {:.4f}\\tMIN Test MovAve Loss: {:.4f}\\n'.format(\n",
    "            max_test_mov_ave_acc[subj, train_run], min_test_mov_ave_loss[subj, train_run]))\n",
    "        \n",
    "        confusion_matrix = model.confusion_matrix((X_test, y_test))\n",
    "        confusion_matrix.savefig(confusion_matrix_path, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print('Confusion Matrix Saved')\n",
    "        \n",
    "        clsf_report = model.classification_report((X_test, y_test))\n",
    "        print(clsf_report)\n",
    "        pd.DataFrame(clsf_report).to_csv(classification_report_path, index=True)\n",
    "        print('Classification Report Saved')\n",
    "\n",
    "        with open(results_path + '/model_performance.npz', 'wb') as model_performance:\n",
    "            np.savez(model_performance,\n",
    "                    train_seed=train_seed, inference_time=inference_time, \n",
    "                    test_acc=test_acc, test_kappa=test_kappa, test_loss=test_loss, min_test_loss=min_test_loss,\n",
    "                    max_test_mov_ave_acc=max_test_mov_ave_acc, min_test_mov_ave_loss=min_test_mov_ave_loss, \n",
    "                    best_runs=best_runs, best_test_acc=best_test_acc, best_test_kappa=best_test_kappa, best_test_loss=best_test_loss, best_min_test_loss=best_min_test_loss,\n",
    "                    best_mov_ave_runs=best_mov_ave_runs, best_max_test_mov_ave_acc=best_max_test_mov_ave_acc, best_min_test_mov_ave_loss=best_min_test_mov_ave_loss)\n",
    "        print('Model Performance Saved')\n",
    "\n",
    "        save_checkpoint(subj+1, train_run+1, file_path=checkpoint_path)\n",
    "        print('-----CHECKPOINT-----')\n",
    "\n",
    "        plt.close('all')\n",
    "    \n",
    "    # SUBJECT SUMMARY\n",
    "    SUBJ_TRAIN_INIT = 1\n",
    "\n",
    "    best_runs[subj] = np.argmax(test_acc[subj,:])\n",
    "    best_test_acc[subj] = test_acc[subj, best_runs[subj]]\n",
    "    best_test_kappa[subj] = test_kappa[subj, best_runs[subj]]\n",
    "    best_test_loss[subj] = test_loss[subj, best_runs[subj]]\n",
    "    best_min_test_loss[subj] = min_test_loss[subj, best_runs[subj]]\n",
    "\n",
    "    best_mov_ave_runs[subj] = np.argmax(max_test_mov_ave_acc[subj,:])\n",
    "    best_max_test_mov_ave_acc[subj] = max_test_mov_ave_acc[subj, best_mov_ave_runs[subj]]\n",
    "    best_min_test_mov_ave_loss[subj] = min_test_mov_ave_loss[subj, best_mov_ave_runs[subj]]\n",
    "\n",
    "    log_write.write('Subject: {:d}'.format(subj+1))\n",
    "    log_write.write('\\tBEST Run: {:d}\\t\\t\\tBEST Test Accuracy: {:.4f}\\tBEST Test Kappa: {:.4f}\\tBEST Test Loss: {:.4f}\\tBEST MIN Test Loss: {:.4f}\\n'.format(\n",
    "        best_runs[subj]+1, best_test_acc[subj], best_test_kappa[subj], best_test_loss[subj], best_min_test_loss[subj]))\n",
    "    log_write.write('\\tBEST MovAve Run: {:d}\\t\\t\\t\\t\\t\\t\\tBEST MAX Test MovAve Accuracy: {:.4f}\\tBEST MIN Test MovAve Loss: {:.4f}\\n'.format(\n",
    "        best_mov_ave_runs[subj]+1, best_max_test_mov_ave_acc[subj], best_min_test_mov_ave_loss[subj]))\n",
    "    log_write.write('\\t\\t\\tAVERAGE Inference Time: {:s} ms'.format(stats(inference_time[subj])))\n",
    "    log_write.write('\\tAVERAGE Test Accuracy: {:s}\\tAVERAGE Test Kappa: {:s}\\tAVERAGE Test Loss: {:s}\\tAVERAGE MIN Test Loss: {:s}'.format(\n",
    "        stats(test_acc[subj]), stats(test_kappa[subj]), stats(test_loss[subj]), stats(min_test_loss[subj])))\n",
    "    log_write.write('\\tAVERAGE MAX Test MovAve Accuracy: {:s}\\tAVERAGE MIN Test MovAve Loss: {:s}\\n'.format(\n",
    "        stats(max_test_mov_ave_acc[subj]), stats(min_test_mov_ave_loss[subj])))\n",
    "\n",
    "    with open(results_path + '/model_performance.npz', 'wb') as model_performance:\n",
    "        np.savez(model_performance,\n",
    "                train_seed=train_seed, inference_time=inference_time, \n",
    "                test_acc=test_acc, test_kappa=test_kappa, test_loss=test_loss, min_test_loss=min_test_loss,\n",
    "                max_test_mov_ave_acc=max_test_mov_ave_acc, min_test_mov_ave_loss=min_test_mov_ave_loss, \n",
    "                best_runs=best_runs, best_test_acc=best_test_acc, best_test_kappa=best_test_kappa, best_test_loss=best_test_loss, best_min_test_loss=best_min_test_loss,\n",
    "                best_mov_ave_runs=best_mov_ave_runs, best_max_test_mov_ave_acc=best_max_test_mov_ave_acc, best_min_test_mov_ave_loss=best_min_test_mov_ave_loss)\n",
    "    print('Model Performance Saved')\n",
    "\n",
    "    save_checkpoint(subj+1, train_run+1, subject_summary=True, file_path=checkpoint_path)\n",
    "    print('-----CHECKPOINT-----')\n",
    "\n",
    "# OVERALL SUMMARY\n",
    "if not OVERALL_SUMMARY:   \n",
    "    log_write.write('\\nSUMMARY\\n')\n",
    "    for subj in range(SUBJECT_SIZE):\n",
    "        log_write.write('Subject: {:d}'.format(subj+1))\n",
    "        log_write.write('\\tBEST Run: {:d}\\tBEST Test Accuracy: {:.4f}\\tBEST Test Kappa: {:.4f}\\tBEST Test Loss: {:.4f}\\tBEST MIN Test Loss: {:.4f}\\n'.format(\n",
    "            best_runs[subj]+1, best_test_acc[subj], best_test_kappa[subj], best_test_loss[subj], best_min_test_loss[subj]))\n",
    "        log_write.write('\\tBEST MovAve Run: {:d}\\t\\t\\t\\t\\tBEST MAX Test MovAve Accuracy: {:.4f}\\tBEST MIN Test MovAve Loss: {:.4f}\\n'.format(\n",
    "            best_mov_ave_runs[subj]+1, best_max_test_mov_ave_acc[subj], best_min_test_mov_ave_loss[subj]))\n",
    "        log_write.write('\\t\\t\\tAVERAGE Inference Time: {:s} ms'.format(stats(inference_time[subj])))\n",
    "        log_write.write('\\tAVERAGE Test Accuracy: {:s}\\tAVERAGE Test Kappa: {:s}\\tAVERAGE Test Loss: {:s}\\tAVERAGE MIN Test Loss: {:s}'.format(\n",
    "            stats(test_acc[subj]), stats(test_kappa[subj]), stats(test_loss[subj]), stats(min_test_loss[subj])))\n",
    "        log_write.write('\\tAVERAGE MAX Test MovAve Accuracy: {:s}\\tAVERAGE MIN Test MovAve Loss: {:s}\\n'.format(\n",
    "            stats(max_test_mov_ave_acc[subj]), stats(min_test_mov_ave_loss[subj])))\n",
    "\n",
    "    log_write.write('\\nAll Subjects - ALL RUNS\\n')\n",
    "    log_write.write('\\t\\tMAX Test Accuracy: {:.4f}\\tMAX Test Kappa: {:.4f}\\tMIN Test Loss: {:.4f}\\tMIN MIN Test Loss: {:.4f}'.format(\n",
    "        np.nanmax(test_acc), np.nanmax(test_kappa), np.nanmin(test_loss), np.nanmin(min_test_loss)))\n",
    "    log_write.write('\\tMAX Test MovAve Accuracy: {:.4f}\\tMIN Test MovAve Loss: {:.4f}\\n'.format(\n",
    "        np.nanmax(max_test_mov_ave_acc), np.nanmin(min_test_mov_ave_loss)))\n",
    "    log_write.write('\\t\\t\\tAVERAGE Inference Time: {:s} ms'.format(stats(inference_time)))\n",
    "    log_write.write('\\tAVERAGE Test Accuracy: {:s}\\tAVERAGE Test Kappa: {:s}\\tAVERAGE Test Loss: {:s}\\tAVERAGE MIN Test Loss: {:s}'.format(\n",
    "        stats(test_acc), stats(test_kappa), stats(test_loss), stats(min_test_loss)))\n",
    "    log_write.write('\\tAVERAGE MAX Test MovAve Accuracy: {:s}\\tAVERAGE MIN Test MovAve Loss: {:s}\\n'.format(\n",
    "        stats(max_test_mov_ave_acc), stats(min_test_mov_ave_loss)))\n",
    "\n",
    "    log_write.write('\\nAll Subjects - BEST RUNS\\n')\n",
    "    log_write.write('\\t\\tMAX Test Accuracy: {:.4f}\\tMAX Test Kappa: {:.4f}\\tMIN Test Loss: {:.4f}\\tMIN MIN Test Loss: {:.4f}'.format(\n",
    "        np.nanmax(best_test_acc), np.nanmax(best_test_kappa), np.nanmin(best_test_loss), np.nanmin(best_min_test_loss)))\n",
    "    log_write.write('\\tMAX Test MovAve Accuracy: {:.4f}\\tMIN Test MovAve Loss: {:.4f}\\n'.format(\n",
    "        np.nanmax(best_max_test_mov_ave_acc), np.nanmin(best_min_test_mov_ave_loss)))\n",
    "    log_write.write('\\t\\tAVERAGE Test Accuracy: {:s}\\tAVERAGE Test Kappa: {:s}\\tAVERAGE Test Loss: {:s}\\tAVERAGE MIN Test Loss: {:s}'.format(\n",
    "        stats(best_test_acc), stats(best_test_kappa), stats(best_test_loss), stats(best_min_test_loss)))\n",
    "    log_write.write('\\tAVERAGE MAX Test MovAve Accuracy: {:s}\\tAVERAGE MIN Test MovAve Loss: {:s}\\n'.format(\n",
    "        stats(best_max_test_mov_ave_acc), stats(best_min_test_mov_ave_loss)))\n",
    "\n",
    "    save_checkpoint(subj+1, train_run+1, subject_summary=True, overall_summary=True, file_path=checkpoint_path)\n",
    "    print('-----CHECKPOINT-----')\n",
    "\n",
    "print('Model Training Complete')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
