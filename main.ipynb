{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T01:06:45.427603Z",
     "iopub.status.busy": "2024-09-19T01:06:45.427406Z",
     "iopub.status.idle": "2024-09-19T01:06:49.210253Z",
     "shell.execute_reply": "2024-09-19T01:06:49.209611Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import time\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import spektral\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score\n",
    "\n",
    "import Model\n",
    "from Model.EEG_Model import AGTCNet\n",
    "from Dataset import config\n",
    "from Dataset.EEGDataset import EEGDataset, EEGSubDataset\n",
    "from Dataset.misc import subject_run_map\n",
    "from utils.analyzer import stats\n",
    "from utils.losses import Loge\n",
    "from utils.callbacks import SimpMovAve\n",
    "from utils.seed import set_seeds\n",
    "from utils.gpu import gpu_allocation\n",
    "from utils.log import Logging, dict_pad, save_checkpoint, load_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T01:06:49.213724Z",
     "iopub.status.busy": "2024-09-19T01:06:49.213590Z",
     "iopub.status.idle": "2024-09-19T01:06:49.273484Z",
     "shell.execute_reply": "2024-09-19T01:06:49.272918Z"
    }
   },
   "outputs": [],
   "source": [
    "GPU_ALLOCATION = None # None | GPU Memory Limit in GB\n",
    "\n",
    "gpu_allocation(GPU_ALLOCATION) if GPU_ALLOCATION else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T01:06:49.276765Z",
     "iopub.status.busy": "2024-09-19T01:06:49.276637Z",
     "iopub.status.idle": "2024-09-19T01:06:49.280341Z",
     "shell.execute_reply": "2024-09-19T01:06:49.279865Z"
    }
   },
   "outputs": [],
   "source": [
    "ONE_HOT = True # Bool\n",
    "# NORM_SCALER: None | instance(BatchNormScaler) from TrainDataset\n",
    "DATASET_PATH = 'RESOURCES'\n",
    "OPTIMIZATION = True\n",
    "\n",
    "EEG_DATASET_CONFIG = {\n",
    "    'ch_selection': None, # None | [CH List]\n",
    "    'ch_adj': ['Defined', 'BCICIV2A'], # 'Defined' | 'Virtual' | '+Laplacian' | '+SelfLoop' | 'FullyConnected' , 'BCICIV2A' | 'EEGMMIDB'\n",
    "    'baseline': None, # None | 'Fixed' | 'Varying'\n",
    "\n",
    "    'resampling': [125, 12], # None | [fs_new, None] | w/ Anti-Aliasing LowPass = [fs_new, lowpass_filt_order = 8~16]\n",
    "    'dc_offset_removal': None, # None | 'mean' | 'mean-filter' | 'norm' | 'norm-filter'\n",
    "    'ch_reference': 'average', # None | 'average' | 1CH\n",
    "\n",
    "    'filter': None, # None | Lowpass: [None, fc_high, filt_order] | Highpass: [fc_low, None, filt_order] | Bandpass: [fc_low, fc_high, filt_order]\n",
    "    'notch_filter': None, # None | [fc_notch, Q_notch = fc_notch / BW_notch]\n",
    "\n",
    "    'filterband': None, # None | [fc_min, fc_max, bw, fc_step, bp_order]\n",
    "    'feature_extraction': None, # None | '[algorithm]': 'EMD' | 'EMD-HHT' | 'STFT'\n",
    "\n",
    "    'normalization': None, # None | 'batch' | 'channel' | 'time' | 'time-batch'\n",
    "\n",
    "    'signal_duration': [2.0, 5.0], # None for Default Dataset tmin & tmax config | [tmin, tmax]\n",
    "    'sample_crop': None, # None | [duration, step]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T01:06:49.283796Z",
     "iopub.status.busy": "2024-09-19T01:06:49.283237Z",
     "iopub.status.idle": "2024-09-19T01:06:49.286141Z",
     "shell.execute_reply": "2024-09-19T01:06:49.285656Z"
    }
   },
   "outputs": [],
   "source": [
    "DATASET = 'BCICIV2A'        # 'BCICIV2A' | 'EEGMMIDB'\n",
    "\n",
    "SUBJECT_SELECTION = 'SN'    # 'SL' | 'SM' | 'SN'\n",
    "SESSION_SELECTION = 'DS'    # 'DS' | 'RS'\n",
    "FINE_TUNING = False         # for 'SL-DS-FT' using 'SN' Top Models as baseline\n",
    "\n",
    "VARY_VALID_RUN = False      # True for DS: LOSeO\n",
    "KFOLD = False               # True for SN: LSSO | False for SN: LOSO \n",
    "\n",
    "CLASS = 4                   # (int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T01:06:49.288888Z",
     "iopub.status.busy": "2024-09-19T01:06:49.288771Z",
     "iopub.status.idle": "2024-09-19T01:06:49.294034Z",
     "shell.execute_reply": "2024-09-19T01:06:49.293594Z"
    }
   },
   "outputs": [],
   "source": [
    "if DATASET == 'BCICIV2A':\n",
    "    SUBJECTS = [subj for subj in range(1, 10)]\n",
    "    VALID_RUN = [[True],\n",
    "                 [False]] # [False, True]\n",
    "\n",
    "    EVENTS = ['Left Hand', 'Right Hand', 'Feet', 'Tongue']\n",
    "    SUBJECT_EXEMPTION = config.dataset_BCICIV2A.subject_exemption\n",
    "    DATALOADER_KWARGS = {}\n",
    "\n",
    "elif DATASET == 'EEGMMIDB':\n",
    "    SUBJECTS = [subj for subj in range(1, 110)]\n",
    "    VALID_RUN = [[4, 6],\n",
    "                 [8, 10],\n",
    "                 [12, 14]]  # [4, 6, 8, 10, 12, 14]\n",
    "\n",
    "    SUBJECT_EXEMPTION = config.dataset_EEGMMIDB.subject_exemption\n",
    "    EVENTS = ['Left Fist', 'Right Fist', 'Both Fists', 'Both Feet']\n",
    "    DATALOADER_KWARGS = {'Epochs_proj': False}\n",
    "    \n",
    "SUBJECT_SIZE = len(SUBJECTS)\n",
    "SUBJECT_SIZE = 1 if (SUBJECT_SELECTION == 'SM') else SUBJECT_SIZE\n",
    "SUBJECT_SIZE = 5 if (SUBJECT_SELECTION == 'SN' and KFOLD) else SUBJECT_SIZE # 20% train-test split\n",
    "\n",
    "EVENTS = EVENTS[:CLASS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T01:06:49.306816Z",
     "iopub.status.busy": "2024-09-19T01:06:49.306401Z",
     "iopub.status.idle": "2024-09-19T01:06:49.311356Z",
     "shell.execute_reply": "2024-09-19T01:06:49.310922Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset(DATASET, SUBJECT_SELECTION, SESSION_SELECTION, SUBJECT, VALID_RUN, SEED=42):\n",
    "\n",
    "    (TRAIN_SUBJECT, TRAIN_RUN), (VALID_SUBJECT, VALID_RUN) = subject_run_map(DATASET, SUBJECT_SELECTION, SESSION_SELECTION, SUBJECT, VALID_RUN)\n",
    "\n",
    "    dataset = EEGDataset(DATASET, {i: TRAIN_RUN for i in TRAIN_SUBJECT}, EVENTS,\n",
    "                        EEG_DATASET_CONFIG, norm_scaler=None,\n",
    "                        one_hot=ONE_HOT, dataset_path=DATASET_PATH,\n",
    "                        optimization=OPTIMIZATION,\n",
    "                        **DATALOADER_KWARGS)\n",
    "\n",
    "    if SESSION_SELECTION == 'RS':\n",
    "        dataset_idx = np.arange(len(dataset))\n",
    "        labels = dataset.labels\n",
    "\n",
    "        train_idx, valid_idx, _, _ = train_test_split(dataset_idx, labels, test_size=0.2, stratify=labels, random_state=SEED)\n",
    "\n",
    "        train_dataset = EEGSubDataset(dataset, train_idx)\n",
    "        valid_dataset = EEGSubDataset(dataset, valid_idx)\n",
    "        test_dataset = valid_dataset\n",
    "\n",
    "        del dataset\n",
    "        \n",
    "    else: # 'DS'\n",
    "        train_dataset = dataset\n",
    "        valid_dataset = EEGDataset(DATASET, {i: VALID_RUN for i in VALID_SUBJECT}, EVENTS,\n",
    "                                EEG_DATASET_CONFIG, norm_scaler=dataset.norm_scaler,\n",
    "                                one_hot=ONE_HOT, dataset_path=DATASET_PATH,\n",
    "                                optimization=OPTIMIZATION,\n",
    "                                **DATALOADER_KWARGS)\n",
    "        test_dataset = valid_dataset\n",
    "\n",
    "    return train_dataset, valid_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T01:06:49.314407Z",
     "iopub.status.busy": "2024-09-19T01:06:49.314189Z",
     "iopub.status.idle": "2024-09-19T01:06:49.329045Z",
     "shell.execute_reply": "2024-09-19T01:06:49.328603Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'AGTCNet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T01:06:49.332029Z",
     "iopub.status.busy": "2024-09-19T01:06:49.331667Z",
     "iopub.status.idle": "2024-09-19T01:06:49.335351Z",
     "shell.execute_reply": "2024-09-19T01:06:49.334919Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_TRAIN = 10\n",
    "LOAD_CHECKPOINT = True\n",
    "\n",
    "KFOLD_SPLIT_SIZE = 5\n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "MOV_WINDOW_SIZE = 20\n",
    "MOV_AVE = True\n",
    "MOV_STD = True\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "LOSS = 'CCE' if CLASS > 2 else 'BCE' # 'BCE' | 'CCE' | 'Loge'\n",
    "\n",
    "OPTIMIZER = 'Adam' # 'Adam' | 'AdamW'\n",
    "if not FINE_TUNING:\n",
    "    LR = 0.001 \n",
    "else:\n",
    "    LR = 0.0005\n",
    "WEIGHT_DECAY = None\n",
    "AMSGRAD = False\n",
    "\n",
    "LR_SCHED_METRIC = 'val_loss' # 'val_loss' | 'mov_ave_val_loss'\n",
    "LR_SCHED_DECAY = 0.9\n",
    "LR_SCHED_MIN = 0.0001\n",
    "LR_SCHED_PATIENCE = 10\n",
    "LR_SCHED_COOLDOWN = 0\n",
    "\n",
    "TARGET_METRIC = 'val_accuracy' # 'val_accuracy' | 'mov_ave_val_accuracy'\n",
    "EARLY_STOP_PATIENCE = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T01:06:49.339027Z",
     "iopub.status.busy": "2024-09-19T01:06:49.338757Z",
     "iopub.status.idle": "2024-09-19T01:17:32.637673Z",
     "shell.execute_reply": "2024-09-19T01:17:32.636930Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "\n",
    "TRAINING_CASE = SUBJECT_SELECTION  if SUBJECT_SELECTION == 'SN' else SUBJECT_SELECTION + '-' + SESSION_SELECTION\n",
    "TRAINING_CASE = TRAINING_CASE + '-FT' if FINE_TUNING else TRAINING_CASE\n",
    "TRAINING_CASE = DATASET +'-'+ TRAINING_CASE\n",
    "results_path = os.path.join(os.getcwd(), '.results', MODEL_NAME, TRAINING_CASE)\n",
    "if not os.path.exists(results_path):\n",
    "    os.makedirs(results_path)\n",
    "checkpoint_path = results_path + '/checkpoint.json'\n",
    "\n",
    "log_write = Logging(results_path + '/log.txt')\n",
    "\n",
    "if LOAD_CHECKPOINT and os.path.exists(checkpoint_path):\n",
    "    # LOAD Last Train Config\n",
    "    SUBJ_INIT, SUBJ_TRAIN_INIT, SUBJ_SUMMARY, OVERALL_SUMMARY = load_checkpoint(file_path=checkpoint_path)\n",
    "\n",
    "    # Load Next Train Config\n",
    "    if SUBJ_SUMMARY:\n",
    "        SUBJ_INIT += 1\n",
    "        SUBJ_TRAIN_INIT = 1\n",
    "    else:\n",
    "        SUBJ_TRAIN_INIT += 1\n",
    "\n",
    "    # Load Checkpoint Data\n",
    "    data = np.load(results_path + '/model_performance.npz')\n",
    "    \n",
    "    train_seed = data['train_seed']\n",
    "    inference_time = data['inference_time']\n",
    "\n",
    "    test_acc = data['test_acc']\n",
    "    test_kappa = data['test_kappa']\n",
    "    test_loss = data['test_loss']\n",
    "    \n",
    "    min_test_loss = data['min_test_loss']\n",
    "    \n",
    "    max_test_mov_ave_acc = data['max_test_mov_ave_acc']\n",
    "    min_test_mov_ave_loss = data['min_test_mov_ave_loss']\n",
    "\n",
    "    best_runs = data['best_runs']\n",
    "    best_test_acc = data['best_test_acc']\n",
    "    best_test_kappa = data['best_test_kappa']\n",
    "    best_test_loss = data['best_test_loss']\n",
    "    best_min_test_loss = data['best_min_test_loss']\n",
    "\n",
    "    best_mov_ave_runs = data['best_mov_ave_runs']\n",
    "    best_max_test_mov_ave_acc = data['best_max_test_mov_ave_acc']\n",
    "    best_min_test_mov_ave_loss = data['best_min_test_mov_ave_loss']\n",
    "\n",
    "    log_write.write('\\n\\n-----LOAD CHECKPOINT-----\\n')\n",
    "\n",
    "    CHECKPOINT_LOADED = True\n",
    "\n",
    "else:\n",
    "    # NO CHECKPOINT\n",
    "    SUBJ_INIT = 1\n",
    "    SUBJ_TRAIN_INIT = 1\n",
    "    OVERALL_SUMMARY = False\n",
    "\n",
    "    log_write.write(MODEL_NAME + '\\t' + TRAINING_CASE + '\\n')\n",
    "\n",
    "    # Initialize Data\n",
    "    train_seed = np.zeros((SUBJECT_SIZE, NUM_TRAIN))\n",
    "    inference_time = np.zeros((SUBJECT_SIZE, NUM_TRAIN))\n",
    "\n",
    "    test_acc = np.zeros((SUBJECT_SIZE, NUM_TRAIN))\n",
    "    test_kappa = np.zeros((SUBJECT_SIZE, NUM_TRAIN))\n",
    "    test_loss = np.zeros((SUBJECT_SIZE, NUM_TRAIN))\n",
    "\n",
    "    min_test_loss = np.zeros((SUBJECT_SIZE, NUM_TRAIN))\n",
    "\n",
    "    max_test_mov_ave_acc = np.zeros((SUBJECT_SIZE, NUM_TRAIN))\n",
    "    min_test_mov_ave_loss = np.zeros((SUBJECT_SIZE, NUM_TRAIN))\n",
    "\n",
    "    best_runs = np.zeros(SUBJECT_SIZE, dtype=np.int8)\n",
    "    best_test_acc = np.zeros(SUBJECT_SIZE)\n",
    "    best_test_kappa = np.zeros(SUBJECT_SIZE)\n",
    "    best_test_loss = np.zeros(SUBJECT_SIZE)\n",
    "    best_min_test_loss = np.zeros(SUBJECT_SIZE)\n",
    "\n",
    "    best_mov_ave_runs = np.zeros(SUBJECT_SIZE, dtype=np.int8)\n",
    "    best_max_test_mov_ave_acc = np.zeros(SUBJECT_SIZE)\n",
    "    best_min_test_mov_ave_loss = np.zeros(SUBJECT_SIZE)\n",
    "\n",
    "    CHECKPOINT_LOADED = False\n",
    "\n",
    "if KFOLD:\n",
    "    kf = KFold(n_splits=KFOLD_SPLIT_SIZE, shuffle=False)\n",
    "    SUBJECT_KFOLD_SPLIT = [kf_split[1]+1 for kf_split in list(kf.split(SUBJECTS))]\n",
    "\n",
    "for subj in range(SUBJ_INIT-1, SUBJECT_SIZE):\n",
    "    log_write.write('\\nTraining Subject {:d}\\n'.format(subj+1))\n",
    "\n",
    "    if subj+1 in SUBJECT_EXEMPTION and (SUBJECT_SELECTION == 'SL' or (SUBJECT_SELECTION == 'SN' and not KFOLD)):\n",
    "        train_seed[subj] = np.full(NUM_TRAIN, np.nan)\n",
    "        inference_time[subj] = np.full(NUM_TRAIN, np.nan)\n",
    "\n",
    "        test_acc[subj] = np.full(NUM_TRAIN, np.nan)\n",
    "        test_kappa[subj] = np.full(NUM_TRAIN, np.nan)\n",
    "        test_loss[subj] = np.full(NUM_TRAIN, np.nan)\n",
    "\n",
    "        min_test_loss[subj] = np.full(NUM_TRAIN, np.nan)\n",
    "\n",
    "        max_test_mov_ave_acc[subj] = np.full(NUM_TRAIN, np.nan)\n",
    "        min_test_mov_ave_loss[subj] = np.full(NUM_TRAIN, np.nan)\n",
    "\n",
    "        best_runs[subj] = 0\n",
    "        best_test_acc[subj] = np.nan\n",
    "        best_test_kappa[subj] = np.nan\n",
    "        best_test_loss[subj] = np.nan\n",
    "        best_min_test_loss[subj] = np.nan\n",
    "\n",
    "        best_mov_ave_runs[subj] = 0\n",
    "        best_max_test_mov_ave_acc[subj] = np.nan\n",
    "        best_min_test_mov_ave_loss[subj] = np.nan\n",
    "        \n",
    "        log_write.write('SKIPPED\\n')\n",
    "\n",
    "        with open(results_path + '/model_performance.npz', 'wb') as model_performance:\n",
    "            np.savez(model_performance,\n",
    "                    train_seed=train_seed, inference_time=inference_time, \n",
    "                    test_acc=test_acc, test_kappa=test_kappa, test_loss=test_loss, min_test_loss=min_test_loss,\n",
    "                    max_test_mov_ave_acc=max_test_mov_ave_acc, min_test_mov_ave_loss=min_test_mov_ave_loss, \n",
    "                    best_runs=best_runs, best_test_acc=best_test_acc, best_test_kappa=best_test_kappa, best_test_loss=best_test_loss, best_min_test_loss=best_min_test_loss,\n",
    "                    best_mov_ave_runs=best_mov_ave_runs, best_max_test_mov_ave_acc=best_max_test_mov_ave_acc, best_min_test_mov_ave_loss=best_min_test_mov_ave_loss)\n",
    "        print('Model Performance Saved')\n",
    "\n",
    "        save_checkpoint(subj+1, NUM_TRAIN, subject_summary=True, file_path=checkpoint_path)\n",
    "        print('-----CHECKPOINT-----')\n",
    "\n",
    "        continue\n",
    "\n",
    "    subject_list = SUBJECT_KFOLD_SPLIT[subj] if (SUBJECT_SELECTION in ['SN'] and KFOLD) else [subj+1]\n",
    "\n",
    "    if SESSION_SELECTION == 'DS' and not VARY_VALID_RUN:\n",
    "        train_dataset, valid_dataset, test_dataset = load_dataset(DATASET, SUBJECT_SELECTION, SESSION_SELECTION, subject_list, VALID_RUN[0])\n",
    "        print('Subject {:d} Dataset Loaded'.format(subj+1))\n",
    "        print(train_dataset, valid_dataset, test_dataset)\n",
    "\n",
    "    subj_path = results_path + '/subj-{:d}'.format(subj+1)\n",
    "    if not os.path.exists(subj_path):\n",
    "        os.makedirs(subj_path)\n",
    "\n",
    "    for train_run in range(SUBJ_TRAIN_INIT-1, NUM_TRAIN):\n",
    "        train_path = subj_path + '/run-{:d}'.format(train_run+1)\n",
    "        best_model_path = train_path + '-best_model.h5'\n",
    "        train_history_path = train_path + '-train_history.csv'\n",
    "        train_plot_path = train_path + '-train_plot.png'\n",
    "        confusion_matrix_path = train_path + '-confusion_matrix.png'\n",
    "        classification_report_path = train_path + '-classification_report.csv'\n",
    "\n",
    "        if VARY_VALID_RUN:\n",
    "            VARY_VALID_RUN_STEP = NUM_TRAIN // len(VALID_RUN)\n",
    "            if ((train_run % VARY_VALID_RUN_STEP) == 0 and (train_run//VARY_VALID_RUN_STEP) < len(VALID_RUN)) or CHECKPOINT_LOADED:\n",
    "                CHECKPOINT_LOADED = False\n",
    "                valid_run_index = train_run//VARY_VALID_RUN_STEP\n",
    "                train_dataset, valid_dataset, test_dataset = load_dataset(DATASET, SUBJECT_SELECTION, SESSION_SELECTION, subject_list, VALID_RUN[valid_run_index])\n",
    "                print('Subject {:d} Dataset {:d} Loaded'.format(subj+1, valid_run_index+1))\n",
    "                print(train_dataset, valid_dataset, test_dataset)\n",
    "        \n",
    "        SEED = np.random.randint(1e4)\n",
    "        set_seeds(SEED)\n",
    "        train_seed[subj, train_run] = SEED\n",
    "        log_write.write('Subject: {:d}\\tTrain No.: {:d}\\tSeed: {:d}'.format(subj+1, train_run+1, SEED))\n",
    "\n",
    "        if SESSION_SELECTION == 'RS':\n",
    "            train_dataset, valid_dataset, test_dataset = load_dataset(DATASET, SUBJECT_SELECTION, SESSION_SELECTION, subject_list, None, SEED=SEED)\n",
    "            print('Subject {:d} Dataset Loaded'.format(subj+1))\n",
    "            print(train_dataset, valid_dataset, test_dataset)\n",
    "\n",
    "        _train_dataset = copy.deepcopy(train_dataset) if SESSION_SELECTION == 'DS' else train_dataset\n",
    "        train_loader = spektral.data.BatchLoader(_train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        valid_loader = spektral.data.BatchLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "        test_loader = valid_loader\n",
    "        print('Batch Loader Loaded')\n",
    "        \n",
    "        model = AGTCNet(train_dataset)\n",
    "        model.build_model().summary()\n",
    "        print('Model Built')\n",
    "\n",
    "        if FINE_TUNING:\n",
    "            it = iter(train_loader)\n",
    "            batch = next(it)\n",
    "            (x, a), y = batch\n",
    "\n",
    "            model((x, a))\n",
    "\n",
    "            tuned_model_SUBJ = subj+1 if not KFOLD else np.argmax([subj+1 in kf_split for kf_split in SUBJECT_KFOLD_SPLIT])+1\n",
    "\n",
    "            tuned_model_TRAINING_CASE = DATASET +'-'+ 'SN'\n",
    "            tuned_model_TRAINING_CASE = tuned_model_TRAINING_CASE + '-KFold' if KFOLD else tuned_model_TRAINING_CASE\n",
    "            tuned_model_results_path = os.path.join(os.getcwd(), '.results', MODEL_NAME, tuned_model_TRAINING_CASE)\n",
    "            \n",
    "            if VARY_VALID_RUN:\n",
    "                data = np.load(tuned_model_results_path + '/model_performance.npz')\n",
    "                tuned_model_acc = data['max_test_mov_ave_acc']\n",
    "                tuned_model_acc = tuned_model_acc[tuned_model_SUBJ-1]\n",
    "                tuned_model_best_runs = np.argsort(tuned_model_acc)[::-1] + 1\n",
    "\n",
    "                VARY_VALID_RUN_STEP = NUM_TRAIN // len(VALID_RUN)\n",
    "                tuned_model_best_run_index = train_run%VARY_VALID_RUN_STEP\n",
    "                tuned_model_path = tuned_model_results_path + '/subj-{:d}/run-{:d}-best_model.h5'.format(tuned_model_SUBJ, tuned_model_best_runs[tuned_model_best_run_index])\n",
    "\n",
    "            else:\n",
    "                tuned_model_path = tuned_model_results_path + '/subj-{:d}/run-{:d}-best_model.h5'.format(tuned_model_SUBJ, train_run+1)\n",
    "            \n",
    "            model.load_weights(tuned_model_path)\n",
    "\n",
    "        model.compile(loss={'BCE': BinaryCrossentropy(), 'CCE': CategoricalCrossentropy(), 'Loge': Loge()}[LOSS],\n",
    "                      optimizer=getattr(optimizers, OPTIMIZER, getattr(optimizers.experimental, OPTIMIZER, None))(learning_rate=LR, weight_decay=WEIGHT_DECAY, amsgrad=AMSGRAD),\n",
    "                      metrics=['accuracy'])\n",
    "        print('Model Compiled')\n",
    "\n",
    "        callbacks = [\n",
    "            ModelCheckpoint(best_model_path, monitor=TARGET_METRIC, mode='max' if 'accuracy' in TARGET_METRIC else 'min' if 'loss' in TARGET_METRIC else None, \n",
    "                            save_best_only=True, save_weights_only=True, verbose=0),\n",
    "\n",
    "            ReduceLROnPlateau(monitor=LR_SCHED_METRIC, mode='max' if 'accuracy' in LR_SCHED_METRIC else 'min' if 'loss' in LR_SCHED_METRIC else None,\n",
    "                              factor=LR_SCHED_DECAY, min_lr=LR_SCHED_MIN,\n",
    "                              patience=LR_SCHED_PATIENCE, cooldown=LR_SCHED_COOLDOWN, verbose=1),\n",
    "            EarlyStopping(monitor=TARGET_METRIC, mode='max' if 'accuracy' in TARGET_METRIC else 'min' if 'loss' in TARGET_METRIC else None, \n",
    "                          patience=EARLY_STOP_PATIENCE, verbose=1),\n",
    "                          \n",
    "            SimpMovAve('accuracy', MOV_WINDOW_SIZE, mov_ave=MOV_AVE, mov_std=MOV_STD), SimpMovAve('loss', MOV_WINDOW_SIZE, mov_ave=MOV_AVE, mov_std=MOV_STD),\n",
    "            ]\n",
    "\n",
    "        history = model.fit(train_loader.load(), steps_per_epoch=train_loader.steps_per_epoch,\n",
    "                            validation_data=valid_loader.load(), validation_steps=valid_loader.steps_per_epoch,\n",
    "                            epochs=EPOCHS, verbose=1, callbacks=callbacks)\n",
    "        \n",
    "        model.plot(mov_ave=MOV_AVE, mov_std=False, grid_on=True).savefig(train_plot_path)\n",
    "        print('Train Plot Saved')\n",
    "\n",
    "        pd.DataFrame(dict_pad(history.history, pad_value=None, pad_pos='leading')).to_csv(train_history_path, index=True)\n",
    "        print('Train History Saved')\n",
    "\n",
    "        model.load_weights(best_model_path)\n",
    "        print('Best Model Loaded')\n",
    "\n",
    "        test_data, test_labels = test_dataset.load()\n",
    "        test_labels_round = np.argmax(test_labels, axis=1)\n",
    "\n",
    "        in_run = time.time()\n",
    "        test_preds = model.predict(test_data)\n",
    "        out_run = time.time()\n",
    "        test_preds = np.argmax(test_preds, axis=1)\n",
    "        inference_time[subj, train_run] = (out_run - in_run) / len(test_labels) * 1000\n",
    "        log_write.write('\\tInference Time: {:.4f} ms'.format(inference_time[subj, train_run]))\n",
    "\n",
    "        test_acc[subj, train_run] = accuracy_score(test_labels_round, test_preds)\n",
    "        test_kappa[subj, train_run] = cohen_kappa_score(test_labels_round, test_preds)\n",
    "        test_loss[subj, train_run] = model.test(test_loader.load(), steps=test_loader.steps_per_epoch)[0]\n",
    "        min_test_loss[subj, train_run] = min(history.history['val_loss'])\n",
    "\n",
    "        max_test_mov_ave_acc[subj, train_run] = max(history.history['mov_ave_val_accuracy'])\n",
    "        min_test_mov_ave_loss[subj, train_run] = min(history.history['mov_ave_val_loss'])\n",
    "        \n",
    "        log_write.write('\\tTest Accuracy: {:.4f}\\tTest Kappa: {:.4f}\\tTest Loss: {:.4f}\\tMIN Test Loss: {:.4f}'.format(\n",
    "            test_acc[subj, train_run], test_kappa[subj, train_run], test_loss[subj, train_run], min_test_loss[subj, train_run]))\n",
    "        log_write.write('\\tMAX Test MovAve Accuracy: {:.4f}\\tMIN Test MovAve Loss: {:.4f}\\n'.format(\n",
    "            max_test_mov_ave_acc[subj, train_run], min_test_mov_ave_loss[subj, train_run]))\n",
    "        \n",
    "        confusion_matrix = model.confusion_matrix(test_dataset.load())\n",
    "        confusion_matrix.savefig(confusion_matrix_path, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print('Confusion Matrix Saved')\n",
    "        \n",
    "        clsf_report = model.classification_report(test_dataset.load())\n",
    "        print(clsf_report)\n",
    "        pd.DataFrame(clsf_report).to_csv(classification_report_path, index=True)\n",
    "        print('Classification Report Saved')\n",
    "\n",
    "        with open(results_path + '/model_performance.npz', 'wb') as model_performance:\n",
    "            np.savez(model_performance,\n",
    "                    train_seed=train_seed, inference_time=inference_time, \n",
    "                    test_acc=test_acc, test_kappa=test_kappa, test_loss=test_loss, min_test_loss=min_test_loss,\n",
    "                    max_test_mov_ave_acc=max_test_mov_ave_acc, min_test_mov_ave_loss=min_test_mov_ave_loss, \n",
    "                    best_runs=best_runs, best_test_acc=best_test_acc, best_test_kappa=best_test_kappa, best_test_loss=best_test_loss, best_min_test_loss=best_min_test_loss,\n",
    "                    best_mov_ave_runs=best_mov_ave_runs, best_max_test_mov_ave_acc=best_max_test_mov_ave_acc, best_min_test_mov_ave_loss=best_min_test_mov_ave_loss)\n",
    "        print('Model Performance Saved')\n",
    "\n",
    "        save_checkpoint(subj+1, train_run+1, file_path=checkpoint_path)\n",
    "        print('-----CHECKPOINT-----')\n",
    "\n",
    "        plt.close('all')\n",
    "\n",
    "        # del _train_dataset\n",
    "    \n",
    "    # SUBJECT SUMMARY\n",
    "    SUBJ_TRAIN_INIT = 1\n",
    "\n",
    "    best_runs[subj] = np.argmax(test_acc[subj,:])\n",
    "    best_test_acc[subj] = test_acc[subj, best_runs[subj]]\n",
    "    best_test_kappa[subj] = test_kappa[subj, best_runs[subj]]\n",
    "    best_test_loss[subj] = test_loss[subj, best_runs[subj]]\n",
    "    best_min_test_loss[subj] = min_test_loss[subj, best_runs[subj]]\n",
    "\n",
    "    best_mov_ave_runs[subj] = np.argmax(max_test_mov_ave_acc[subj,:])\n",
    "    best_max_test_mov_ave_acc[subj] = max_test_mov_ave_acc[subj, best_mov_ave_runs[subj]]\n",
    "    best_min_test_mov_ave_loss[subj] = min_test_mov_ave_loss[subj, best_mov_ave_runs[subj]]\n",
    "\n",
    "    log_write.write('Subject: {:d}'.format(subj+1))\n",
    "    log_write.write('\\tBEST Run: {:d}\\t\\t\\tBEST Test Accuracy: {:.4f}\\tBEST Test Kappa: {:.4f}\\tBEST Test Loss: {:.4f}\\tBEST MIN Test Loss: {:.4f}\\n'.format(\n",
    "        best_runs[subj]+1, best_test_acc[subj], best_test_kappa[subj], best_test_loss[subj], best_min_test_loss[subj]))\n",
    "    log_write.write('\\tBEST MovAve Run: {:d}\\t\\t\\t\\t\\t\\t\\tBEST MAX Test MovAve Accuracy: {:.4f}\\tBEST MIN Test MovAve Loss: {:.4f}\\n'.format(\n",
    "        best_mov_ave_runs[subj]+1, best_max_test_mov_ave_acc[subj], best_min_test_mov_ave_loss[subj]))\n",
    "    log_write.write('\\t\\t\\tAVERAGE Inference Time: {:s} ms'.format(stats(inference_time[subj])))\n",
    "    log_write.write('\\tAVERAGE Test Accuracy: {:s}\\tAVERAGE Test Kappa: {:s}\\tAVERAGE Test Loss: {:s}\\tAVERAGE MIN Test Loss: {:s}'.format(\n",
    "        stats(test_acc[subj]), stats(test_kappa[subj]), stats(test_loss[subj]), stats(min_test_loss[subj])))\n",
    "    log_write.write('\\tAVERAGE MAX Test MovAve Accuracy: {:s}\\tAVERAGE MIN Test MovAve Loss: {:s}\\n'.format(\n",
    "        stats(max_test_mov_ave_acc[subj]), stats(min_test_mov_ave_loss[subj])))\n",
    "\n",
    "    with open(results_path + '/model_performance.npz', 'wb') as model_performance:\n",
    "        np.savez(model_performance,\n",
    "                train_seed=train_seed, inference_time=inference_time, \n",
    "                test_acc=test_acc, test_kappa=test_kappa, test_loss=test_loss, min_test_loss=min_test_loss,\n",
    "                max_test_mov_ave_acc=max_test_mov_ave_acc, min_test_mov_ave_loss=min_test_mov_ave_loss, \n",
    "                best_runs=best_runs, best_test_acc=best_test_acc, best_test_kappa=best_test_kappa, best_test_loss=best_test_loss, best_min_test_loss=best_min_test_loss,\n",
    "                best_mov_ave_runs=best_mov_ave_runs, best_max_test_mov_ave_acc=best_max_test_mov_ave_acc, best_min_test_mov_ave_loss=best_min_test_mov_ave_loss)\n",
    "    print('Model Performance Saved')\n",
    "\n",
    "    save_checkpoint(subj+1, train_run+1, subject_summary=True, file_path=checkpoint_path)\n",
    "    print('-----CHECKPOINT-----')\n",
    "\n",
    "# OVERALL SUMMARY\n",
    "if not OVERALL_SUMMARY:   \n",
    "    log_write.write('\\nSUMMARY\\n')\n",
    "    for subj in range(SUBJECT_SIZE):\n",
    "        log_write.write('Subject: {:d}'.format(subj+1))\n",
    "        log_write.write('\\tBEST Run: {:d}\\tBEST Test Accuracy: {:.4f}\\tBEST Test Kappa: {:.4f}\\tBEST Test Loss: {:.4f}\\tBEST MIN Test Loss: {:.4f}\\n'.format(\n",
    "            best_runs[subj]+1, best_test_acc[subj], best_test_kappa[subj], best_test_loss[subj], best_min_test_loss[subj]))\n",
    "        log_write.write('\\tBEST MovAve Run: {:d}\\t\\t\\t\\t\\tBEST MAX Test MovAve Accuracy: {:.4f}\\tBEST MIN Test MovAve Loss: {:.4f}\\n'.format(\n",
    "            best_mov_ave_runs[subj]+1, best_max_test_mov_ave_acc[subj], best_min_test_mov_ave_loss[subj]))\n",
    "        log_write.write('\\t\\t\\tAVERAGE Inference Time: {:s} ms'.format(stats(inference_time[subj])))\n",
    "        log_write.write('\\tAVERAGE Test Accuracy: {:s}\\tAVERAGE Test Kappa: {:s}\\tAVERAGE Test Loss: {:s}\\tAVERAGE MIN Test Loss: {:s}'.format(\n",
    "            stats(test_acc[subj]), stats(test_kappa[subj]), stats(test_loss[subj]), stats(min_test_loss[subj])))\n",
    "        log_write.write('\\tAVERAGE MAX Test MovAve Accuracy: {:s}\\tAVERAGE MIN Test MovAve Loss: {:s}\\n'.format(\n",
    "            stats(max_test_mov_ave_acc[subj]), stats(min_test_mov_ave_loss[subj])))\n",
    "\n",
    "    log_write.write('\\nAll Subjects - ALL RUNS\\n')\n",
    "    log_write.write('\\t\\tMAX Test Accuracy: {:.4f}\\tMAX Test Kappa: {:.4f}\\tMIN Test Loss: {:.4f}\\tMIN MIN Test Loss: {:.4f}'.format(\n",
    "        np.nanmax(test_acc), np.nanmax(test_kappa), np.nanmin(test_loss), np.nanmin(min_test_loss)))\n",
    "    log_write.write('\\tMAX Test MovAve Accuracy: {:.4f}\\tMIN Test MovAve Loss: {:.4f}\\n'.format(\n",
    "        np.nanmax(max_test_mov_ave_acc), np.nanmin(min_test_mov_ave_loss)))\n",
    "    log_write.write('\\t\\t\\tAVERAGE Inference Time: {:s} ms'.format(stats(inference_time)))\n",
    "    log_write.write('\\tAVERAGE Test Accuracy: {:s}\\tAVERAGE Test Kappa: {:s}\\tAVERAGE Test Loss: {:s}\\tAVERAGE MIN Test Loss: {:s}'.format(\n",
    "        stats(test_acc), stats(test_kappa), stats(test_loss), stats(min_test_loss)))\n",
    "    log_write.write('\\tAVERAGE MAX Test MovAve Accuracy: {:s}\\tAVERAGE MIN Test MovAve Loss: {:s}\\n'.format(\n",
    "        stats(max_test_mov_ave_acc), stats(min_test_mov_ave_loss)))\n",
    "\n",
    "    log_write.write('\\nAll Subjects - BEST RUNS\\n')\n",
    "    log_write.write('\\t\\tMAX Test Accuracy: {:.4f}\\tMAX Test Kappa: {:.4f}\\tMIN Test Loss: {:.4f}\\tMIN MIN Test Loss: {:.4f}'.format(\n",
    "        np.nanmax(best_test_acc), np.nanmax(best_test_kappa), np.nanmin(best_test_loss), np.nanmin(best_min_test_loss)))\n",
    "    log_write.write('\\tMAX Test MovAve Accuracy: {:.4f}\\tMIN Test MovAve Loss: {:.4f}\\n'.format(\n",
    "        np.nanmax(best_max_test_mov_ave_acc), np.nanmin(best_min_test_mov_ave_loss)))\n",
    "    log_write.write('\\t\\tAVERAGE Test Accuracy: {:s}\\tAVERAGE Test Kappa: {:s}\\tAVERAGE Test Loss: {:s}\\tAVERAGE MIN Test Loss: {:s}'.format(\n",
    "        stats(best_test_acc), stats(best_test_kappa), stats(best_test_loss), stats(best_min_test_loss)))\n",
    "    log_write.write('\\tAVERAGE MAX Test MovAve Accuracy: {:s}\\tAVERAGE MIN Test MovAve Loss: {:s}\\n'.format(\n",
    "        stats(best_max_test_mov_ave_acc), stats(best_min_test_mov_ave_loss)))\n",
    "\n",
    "    save_checkpoint(subj+1, train_run+1, subject_summary=True, overall_summary=True, file_path=checkpoint_path)\n",
    "    print('-----CHECKPOINT-----')\n",
    "\n",
    "print('Model Training Complete')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
